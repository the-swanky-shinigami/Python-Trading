import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
from dateutil.relativedelta import relativedelta

# Initialize an empty DataFrame to store all data
all_data = pd.DataFrame()

# Start and end dates
start_date = datetime(2007, 4, 1)  # April 2007
end_date = datetime(2024, 9, 1)    # September 2024

# Loop through each month from start_date to end_date
current_date = start_date
while current_date <= end_date:
    # Construct the URL with current month and year
    url = f"https://www.moneycontrol.com/techmvc/responsive/fiidii/monthly?month={current_date.month:02d}&year={current_date.year}&section=cash&sub_section="

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'X-Requested-With': 'XMLHttpRequest',
        'Referer': 'https://www.moneycontrol.com/stocks/marketstats/fii_dii_activity/index.php',
        'Cookie': 'MC_PPID_LOGIC=normaluser25774575217216576mcids; A18ID=1728301992367.217557; PHPSESSID=ov1nup9q53j0b2dj9qso522f00; _abck=9C98D5C46BC235421C8D0E773A875C67~0~YAAQbAkgF8MZvDWSAQAAypuvZwxOGhgKm4A8Lk8mlKHujrduC/ZJzlHgg6mCCOPG1UGy+QWOS44nzrfW/PFznPljN2ssjS/b640SZnGPgPsWD2J2ovfNsHG0wJqyRLyH5bh2EsDE+V9eQHsA1a6nsekMhLpWE60j8ZHkzrjzoAIydXJ2BwV7591/VGgj+MkJVnKbRuuTX8YX5JViUFqGa0+XTuXcj8EBR3RFODdi58T8oQk4lAuEMJ/ma1Ag+VDna32UQfwC79aIPESSrB7RyAGT/XqtZOXg7j4Fu6yxCN1OXM50cGonsWqONLL8K6qbeMJ2de9fzksXPeatgr0B/Wls6D8luwq7/vy0tYX0xWX+XE/SOC/RTbAN2pTWs38rJd4zipdFPKlpLTAyZ+rJwQryWmrgFDUQ6zyDLVRu~-1~-1~1724944322; bm_sz=6B47ADAFC94C621C19902F2B25B2C1CD~YAAQbAkgF8UZvDWSAQAAypuvZxkqLRART8HR1CJSkuLZoz1nNUAiajFLDQoJT0PBSk4BcpsnCwrzUUY5UY8EJM0NdYlpulMMrxTvTJW5qfwNY8RV/Pzfs2dcawBFnaO3/hToD2ixkyPufR4wK3xqLg+WUOB6uUg3in0KUqWwTHH7O2qNcP+KddFcp07IlT1uiDWe4vcA7ArzBfiBoIpnWcl60eICA1BLP3iz7ZtrUarKqQvy/BkK8iuQQOHpgsU36Y5XZ7tdXUf7tWokm9Gvr5KGdqcwHbnd8RzmoOHHVeuPD3ghsfrXc/mFsoMU2W6B62f2vZ8sVASJ40uhUVdiP4DiNEfIfTx30VRRQ36r2NpfEYjDs6FH5sXolgvfKg==~3618353~4539956; dtCookie=v_4_srv_5_sn_B1F5F37A0778CABDD1921BCD3B56C50B_perc_100000_ol_0_mul_1_app-3A15ca68b27f59163f_1; ak_bmsc=9FBC6D95C5DBC50F3A8D017A4F4BB73F~000000000000000000000000000000~YAAQ0XbNFxiLf2eSAQAANhS0ZxmiMZqb9mViXKvdcYGFEMPnxIJfm16PpJzE5yVEspsr2CSTswze+bB2IGGKhW61WKPWYNkvxaKw3NPzPXPfWGjfF/hYSPfCS0zTHQL5E5JvUsuu2KxgMZeXC9Rw/TjL86ZQ7IJppRsE1D1P+uXsN53R2fmXp0rT8O23C7PSfaGI/Nl1TWemdczb10n4D6DbViI+MSJDAgK1U7r22VTVl9f1ATWXRRtlaa+iT+48n9srC0XFAgLXmGBHMesVEzDg+rthobMtRWZ/XpTXDSDrLuDy5QUzctWkspdaVqWuVkjLbDE6/aprfeeEcuIsjUsoXmt75aVfGXV9Vi+9NCBirdo8pendR2TyGIlZ4/K4hRrt/u7T+zf83b6uLDXdF20=',  # Paste cookies from browser
    }

    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    table = soup.find('table')
    rows = table.find_all('tr')

    # Extract header
    headers = []
    for th in rows[1].find_all('th'):
        headers.append(th.text.strip())

    # Extract data
    data = []
    for row in rows[2:]:
        cols = row.find_all(['td', 'th'])
        data.append([col.text.strip() for col in cols])

    # Create a DataFrame
    df = pd.DataFrame(data, columns=headers)

    # Delete the first row of the database
    df = df.drop(df.index[0])

    # Reverse the order of the dataframe
    df = df.iloc[::-1]

    # Append the data to the all_data DataFrame
    all_data = pd.concat([all_data, df], ignore_index=True)

    # Move to the next month
    current_date += relativedelta(months=1)

# Export the collected data to an Excel file
output_file = "/content/drive/MyDrive/fii_dii_data.xlsx" #Change the directory accordingly
all_data.to_excel(output_file, index=False)

print("Data has been successfully scraped and saved to the Excel file.")
