{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kF41dNjDgu2o"},"outputs":[],"source":["import pandas as pd\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O9D2QjdTjlMP"},"outputs":[],"source":["# Function to read stock data from an Excel file and skip the first 100 days\n","def get_stock_data_from_excel(file_path):\n","    all_stock_data = pd.read_excel(file_path, sheet_name=None)\n","    stock_data = {}\n","\n","    # Get all sheet names\n","    all_sheets = list(all_stock_data.keys())\n","\n","    # Get sheet names starting from the 150th sheet (if needed, uncomment)\n","    # sheets_to_read = all_sheets[150:]\n","    sheets_to_read = all_sheets\n","\n","    for sheet_name in sheets_to_read:\n","        data = all_stock_data[sheet_name]\n","        data['Date'] = pd.to_datetime(data['Date'])\n","        data.set_index('Date', inplace=True)\n","\n","        # Skip the first 100 rows (assuming one row per day)\n","        data = data.iloc[100:]\n","\n","        stock_data[sheet_name] = data\n","\n","    return stock_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Y3ghIyojmyO"},"outputs":[],"source":["# Function to read EMA combinations from an Excel file\n","def get_ema_combinations(file_path):\n","    return pd.read_excel(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nEL3io5DjoIZ"},"outputs":[],"source":["# Function to calculate EMA for a given stock's dataframe\n","def calculate_ema(data, period):\n","    return data['Close'].ewm(span=period, adjust=False).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZ_0e8B-jrOT"},"outputs":[],"source":["# Function to calculate MACD and signal line\n","def calculate_macd(data, fast_ema_period, slow_ema_period, signal_period):\n","    data['EMA_' + str(fast_ema_period)] = calculate_ema(data, fast_ema_period)\n","    data['EMA_' + str(slow_ema_period)] = calculate_ema(data, slow_ema_period)\n","    data['MACD'] = data['EMA_' + str(fast_ema_period)] - data['EMA_' + str(slow_ema_period)]\n","    data['Signal Line'] = data['MACD'].ewm(span=signal_period, adjust=False).mean()\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JUHRNCLikKsb"},"outputs":[],"source":["# Function to create SCRIP DataFrame based on MACD crossover signals\n","def create_scrip_dataframe(data, fast_ema_period, slow_ema_period, signal_period):\n","    data = calculate_macd(data, fast_ema_period, slow_ema_period, signal_period)\n","\n","    # Generate 'Long' or 'Short' signals based on MACD and Signal Line crossovers\n","    data['Long / Short'] = data.apply(lambda row: 'Long' if row['MACD'] > row['Signal Line'] else 'Short', axis=1)\n","\n","    # Initialize Signal No. and increment on position change\n","    data['Signal No.'] = 0\n","    signal_no = 0\n","    previous_position = None\n","    for i in range(len(data)):\n","        current_position = data.iloc[i]['Long / Short']\n","        if current_position != previous_position:\n","            signal_no += 1\n","        data.at[data.index[i], 'Signal No.'] = signal_no\n","        previous_position = current_position\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Er8kNQPYkMvT"},"outputs":[],"source":["# Function to create the Trade_Results DataFrame collectively for all trades (Entry at the Open)\n","def create_trade_results(scrip_df):\n","    trades=[]\n","    grouped = scrip_df.groupby('Signal No.')\n","\n","    for signal_no, group in grouped:\n","        #Don't process signals below signal number 3 and ignore them\n","        if signal_no < 3:\n","            continue\n","\n","        #Exclude the last signal for all trades combined\n","        if signal_no == scrip_df['Signal No.'].max():\n","            break\n","\n","        entry = group.iloc[0]\n","        next_signal_entry = grouped.get_group(signal_no + 1).iloc[0]\n","\n","        #Get the original signal\n","        original_signal = entry['Long / Short']\n","\n","        #Entry at the open\n","        entry_index = scrip_df.index.get_loc(entry.name) + 1\n","        exit_index = scrip_df.index.get_loc(next_signal_entry.name) + 1\n","\n","        # Ensure the index is within bounds\n","        if entry_index >= len(scrip_df) or exit_index >= len(scrip_df):\n","            continue\n","\n","        entry_row = scrip_df.iloc[entry_index]\n","        exit_row = scrip_df.iloc[exit_index]\n","\n","        #New entry and exit based on entry at the open\n","        entry_date = entry_row.name\n","        exit_date = exit_row.name\n","\n","        entry_price = entry_row['Open']\n","        exit_price = exit_row['Open']\n","\n","        #Calculate the duration of the trade\n","        days_in_trade = (exit_date - entry_date).days\n","\n","        # Determine if the signal is a whipsaw signal\n","        whipsaw_signal_count = scrip_df[scrip_df['Signal No.'] == signal_no].shape[0]\n","        whipsaw_signal = 'YES' if whipsaw_signal_count == 1 else 'NO'\n","\n","        # Determine the range of the trade while excluding the entry date\n","        period_data = scrip_df[(scrip_df.index >= entry_date) & (scrip_df.index < exit_date)]\n","\n","        # Calculate highest or lowest point based on signal type\n","        highest_lowest_point = period_data['High'].max() if original_signal == 'Long' else period_data['Low'].min()\n","        highest_point_percent = ((highest_lowest_point - entry_price) / entry_price * 100) if original_signal == 'Long' else ((entry_price - highest_lowest_point) / entry_price * 100)\n","\n","        # Determine if the highest point occured on the opening day\n","        opening_highest = 'YES' if highest_lowest_point <= 0.0 else 'NO'\n","\n","        trades.append({\n","            'Signal No.': signal_no,\n","            'Type of Signal': original_signal,\n","            'Entry Date': entry_date,\n","            'Exit Date': exit_date,\n","            'Entry Price': entry_price,\n","            'Exit Price': exit_price,\n","            'Days in Trade': days_in_trade,\n","            'Pure Signal P&L': 0.0,  # Placeholder, will be calculated separately\n","            'Pure Signal Won/Lost': '',  # Placeholder, will be calculated separately\n","            'Highest Point/Lowest Point': highest_lowest_point,\n","            'Highest Point %': highest_point_percent,\n","            'Opening = Highest': opening_highest,\n","            'Whipsaw Signal': whipsaw_signal,\n","            'Opening Equity': 0.0,  # Placeholder, will be calculated separately\n","            'Shares Bought': 0,  # Placeholder, will be calculated separately\n","            'Total Price Paid': 0.0,  # Placeholder, will be calculated separately\n","            'Total Price Got': 0.0,  # Placeholder, will be calculated separately\n","            'Transaction Cost': 0.0,  # Placeholder, will be calculated separately\n","            'Closing Equity': 0.0,  # Placeholder, will be calculated separately\n","        })\n","\n","    trade_results_df = pd.DataFrame(trades)\n","    return trade_results_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wz1ksl9DkP1H"},"outputs":[],"source":["# Function to calculate financial metrics for a given trade results DataFrame\n","def calculate_financial_metrics(trade_results_df, starting_equity):\n","    previous_equity = starting_equity\n","    for i, row in trade_results_df.iterrows():\n","        shares_bought = round(previous_equity / row['Entry Price'])\n","        total_price_paid = shares_bought * row['Entry Price']\n","        total_price_got = shares_bought * row['Exit Price']\n","        transaction_cost = total_price_paid * 0.002\n","        pnl = ((row['Exit Price'] - row['Entry Price']) * shares_bought) - transaction_cost if row['Type of Signal'] == 'Long' else ((row['Entry Price'] - row['Exit Price']) * shares_bought) - transaction_cost\n","        won_lost = 'Won' if pnl > 0 else 'Lost'\n","        closing_equity = previous_equity + pnl\n","\n","        # Update the dataframe\n","        trade_results_df.at[i, 'Opening Equity'] = previous_equity\n","        trade_results_df.at[i, 'Shares Bought'] = shares_bought\n","        trade_results_df.at[i, 'Total Price Paid'] = total_price_paid\n","        trade_results_df.at[i, 'Total Price Got'] = total_price_got\n","        trade_results_df.at[i, 'Transaction Cost'] = transaction_cost\n","        trade_results_df.at[i, 'Pure Signal P&L'] = pnl\n","        trade_results_df.at[i, 'Pure Signal Won/Lost'] = won_lost\n","        trade_results_df.at[i, 'Closing Equity'] = closing_equity\n","\n","        previous_equity = closing_equity\n","\n","    return trade_results_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIGnCTXkkRPU"},"outputs":[],"source":["# Function to create the Analysis DataFrame for a given set of trades\n","def create_analysis_dataframe(trade_results_df, signal_type, stock_symbol, fast_ema, slow_ema, signal_period, starting_equity):\n","    total_trades = len(trade_results_df)\n","    winning_trades = trade_results_df[trade_results_df['Pure Signal Won/Lost'] == 'Won']\n","    losing_trades = trade_results_df[trade_results_df['Pure Signal Won/Lost'] == 'Lost']\n","    winning_percentage = (len(winning_trades) / total_trades) * 100 if total_trades > 0 else 0\n","    losing_percentage = (len(losing_trades) / total_trades) * 100 if total_trades > 0 else 0\n","    num_whipsaws = trade_results_df[trade_results_df['Whipsaw Signal'] == 'Yes'].shape[0]\n","    num_opening_highest = trade_results_df[trade_results_df['Opening = Highest'] == 'Yes'].shape[0]\n","    twentieth_percentile = trade_results_df['Highest Point %'].quantile(0.2) if total_trades > 0 else 0\n","\n","    # Calculate CAGR (Compound Annual Growth Rate)\n","    if total_trades > 0:\n","        num_years = trade_results_df['Days in Trade'].sum() / 365\n","        ending_equity = trade_results_df.iloc[-1]['Closing Equity']\n","        cagr = (((ending_equity / starting_equity) ** (1 / num_years)) - 1) * 100 if num_years > 0 else 0\n","    else:\n","        cagr = 0\n","\n","    analysis_data = {\n","        'Scrip Name': stock_symbol,\n","        'Fast EMA': fast_ema,\n","        'Slow EMA': slow_ema,\n","        'Signal Period': signal_period,\n","        '# Signals': total_trades,\n","        'Signal Type': signal_type,\n","        'CAGR- Return': cagr,\n","        'Winning %': winning_percentage,\n","        'Losing %': losing_percentage,\n","        '# Whipsaws': num_whipsaws,\n","        '# Opening = Highest': num_opening_highest,\n","        '20th Percentile': twentieth_percentile\n","    }\n","    analysis_df = pd.DataFrame([analysis_data])\n","    return analysis_df, twentieth_percentile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ch2cr9gIrJks"},"outputs":[],"source":["def new_trade_results(scrip_df, twentieth_percentile_long, twentieth_percentile_short):\n","    new_trades = []\n","\n","    grouped = scrip_df.groupby('Signal No.')\n","\n","    for signal_no, group in grouped:\n","        #Don't process signals below signal number 3 and ignore them\n","        if signal_no < 3:\n","            continue\n","\n","        #Exclude the last signal for all trades combined\n","        if signal_no == scrip_df['Signal No.'].max():\n","            break\n","\n","        entry = group.iloc[0]\n","        next_signal_entry = grouped.get_group(signal_no + 1).iloc[0]\n","\n","        #Get the original signal\n","        original_signal = entry['Long / Short']\n","\n","        #Entry at the open\n","        entry_index = scrip_df.index.get_loc(entry.name) + 1\n","        exit_index = scrip_df.index.get_loc(next_signal_entry.name) + 1\n","\n","        # Ensure the index is within bounds\n","        if entry_index >= len(scrip_df) or exit_index >= len(scrip_df):\n","            continue\n","\n","        entry_row = scrip_df.iloc[entry_index]\n","        exit_row = scrip_df.iloc[exit_index]\n","\n","        #New entry and exit based on entry at the open\n","        entry_date = entry_row.name\n","        exit_date = exit_row.name\n","\n","        entry_price = entry_row['Open']\n","        exit_price = exit_row['Open']\n","\n","        #Calculate the duration of the trade\n","        days_in_trade = (exit_date - entry_date).days\n","\n","        # Determine range of trade\n","        period_data = scrip_df[(scrip_df.index >= entry_date) & (scrip_df.index < exit_date)]\n","\n","        # Initialize the variables\n","        highest_point_percent = 0.0\n","        lowest_point_percent = 0.0\n","        achieved_20th_percentile = ''\n","        opening_highest = ''\n","        opening_lowest = ''\n","\n","        # Calculate highest point percentage based on signal type\n","        if original_signal == 'Long':\n","            highest_point = period_data['High'].max()\n","            highest_point_percent = ((highest_point - entry_price) / entry_price * 100)\n","            achieved_20th_percentile = 'YES' if highest_point_percent >= twentieth_percentile_long else 'NO'\n","            opening_highest = 'YES' if highest_point_percent <= 0.0 else 'NO'\n","        else:\n","            lowest_point = period_data['Low'].min()\n","            lowest_point_percent = ((entry_price - lowest_point) / entry_price * 100)\n","            achieved_20th_percentile = 'YES' if lowest_point_percent >= twentieth_percentile_short else 'NO'\n","            opening_lowest = 'YES' if lowest_point_percent <= 0.0 else 'NO'\n","\n","        # Initialize more variables\n","\n","        date_of_highest_point = ''\n","\n","        days_to_reach_highest_point = ''\n","        days_to_reach_lowest_point = ''\n","\n","        date_of_lowest_point = ''\n","\n","        # Find the date of highest and lowest point\n","        if achieved_20th_percentile == 'YES':\n","            if original_signal == 'Long':\n","                date_of_highest_point = period_data[period_data['High'] == highest_point].index[0]\n","                days_to_reach_highest_point = (date_of_highest_point - entry_date).days\n","            else:\n","                date_of_lowest_point = period_data[period_data['Low'] == lowest_point].index[0]\n","                days_to_reach_lowest_point = (date_of_lowest_point - entry_date).days\n","\n","        new_trades.append({\n","            'Signal No.': signal_no,\n","            'Type of Signal': original_signal,\n","            'Entry Date': entry_date,\n","            'Exit Date': exit_date,\n","            'Entry Price': entry_price,\n","            'Exit Price': exit_price,\n","            'Days in Trade': days_in_trade,\n","            'Highest Point' if original_signal == 'Long' else 'Lowest Point': highest_point if original_signal == 'Long' else lowest_point,\n","            'Highest Point %' if original_signal == 'Long' else 'Lowest Point %': highest_point_percent if original_signal == 'Long' else lowest_point_percent,\n","            'Date of reaching Highest Point' if original_signal == 'Long' else 'Date of reaching Lowest Point': date_of_highest_point if original_signal == 'Long' else date_of_lowest_point,\n","            'Days for reaching Highest Point' if original_signal == 'Long' else 'Days for reaching Lowest Point': days_to_reach_highest_point if original_signal == 'Long' else days_to_reach_lowest_point,\n","            '20th Percentile Reached?': achieved_20th_percentile,\n","            'Opening = Highest' if original_signal == 'Long' else 'Opening = Lowest': opening_highest if original_signal == 'Long' else opening_lowest\n","        })\n","\n","    #Convert to dataframe\n","    new_trades_df = pd.DataFrame(new_trades)\n","    return new_trades_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"som2B_O5rK5I"},"outputs":[],"source":["def success_sheet(scrip_df, new_long_20th_achieved_df, new_short_20th_achieved_df, twentieth_percentile_long, twentieth_percentile_short):\n","    # Extract relevant columns from long and short trades dataframes\n","    long_success = new_long_20th_achieved_df[['Signal No.', 'Type of Signal', 'Entry Date', 'Exit Date', 'Entry Price', 'Highest Point', 'Highest Point %', 'Date of reaching Highest Point', 'Days for reaching Highest Point', '20th Percentile Reached?', 'Opening = Highest']].copy()\n","    short_success = new_short_20th_achieved_df[['Signal No.', 'Type of Signal', 'Entry Date', 'Exit Date', 'Entry Price', 'Lowest Point', 'Lowest Point %', 'Date of reaching Lowest Point', 'Days for reaching Lowest Point', '20th Percentile Reached?', 'Opening = Lowest']].copy()\n","\n","    # Add Column for Target for 20th Percentile\n","    long_success.loc[:, 'Target for 20th Percentile'] = long_success['Entry Price'] * (1 + twentieth_percentile_long / 100)\n","    short_success.loc[:, 'Target for 20th Percentile'] = short_success['Entry Price'] * (1 - twentieth_percentile_short / 100)   # NEW CHANGE\n","\n","    # Add column for Target Reached On\n","    long_success.loc[:, 'Target Reached On'] = long_success.apply(\n","        lambda row: scrip_df[\n","            (scrip_df['Signal No.'] == row['Signal No.']) &\n","            (scrip_df['High'] >= row['Target for 20th Percentile']) &\n","            (scrip_df.index >= row['Entry Date'])\n","        ].index.min() if not scrip_df[\n","            (scrip_df['Signal No.'] == row['Signal No.']) &\n","            (scrip_df['High'] >= row['Target for 20th Percentile']) &\n","            (scrip_df.index >= row['Entry Date'])\n","        ].empty else None,\n","        axis=1\n","    )\n","\n","    short_success.loc[:, 'Target Reached On'] = short_success.apply(\n","        lambda row: scrip_df[\n","            (scrip_df['Signal No.'] == row['Signal No.']) &\n","            (scrip_df['Low'] <= row['Target for 20th Percentile']) &\n","            (scrip_df.index >= row['Entry Date'])\n","        ].index.min() if not scrip_df[\n","            (scrip_df['Signal No.'] == row['Signal No.']) &\n","            (scrip_df['Low'] <= row['Target for 20th Percentile']) &\n","            (scrip_df.index >= row['Entry Date'])\n","        ].empty else None,\n","        axis=1\n","    )\n","\n","    # Add column for Days for 20th Percentile\n","    long_success.loc[:, 'Days for 20th Percentile'] = long_success.apply(lambda row: (row['Target Reached On'] - row['Entry Date']).days if pd.notnull(row['Target Reached On']) else None, axis=1)\n","    short_success.loc[:, 'Days for 20th Percentile'] = short_success.apply(lambda row: (row['Target Reached On'] - row['Entry Date']).days if pd.notnull(row['Target Reached On']) else None, axis=1)\n","\n","    # Add column for Lowest point on the way to the 20th Percentile\n","    long_success.loc[:, 'Lowest point on the way to the 20th Percentile'] = long_success.apply(lambda row: scrip_df[(scrip_df['Signal No.'] == row['Signal No.']) & (scrip_df.index >= row['Entry Date']) & (scrip_df.index <= row['Target Reached On'])]['Low'].min() if pd.notnull(row['Target Reached On']) else None, axis=1)\n","    short_success.loc[:, 'Highest point on the way to the 20th Percentile'] = short_success.apply(lambda row: scrip_df[(scrip_df['Signal No.'] == row['Signal No.']) & (scrip_df.index >= row['Entry Date']) & (scrip_df.index <= row['Target Reached On'])]['High'].max() if pd.notnull(row['Target Reached On']) else None, axis=1)\n","\n","    # Add column for Lowest Point %\n","    long_success.loc[:, 'Lowest Point %'] = long_success.apply(lambda row: (row['Lowest point on the way to the 20th Percentile'] - row['Entry Price']) / row['Entry Price'] * 100 if pd.notnull(row['Lowest point on the way to the 20th Percentile']) else None, axis=1)\n","    short_success.loc[:, 'Highest Point %'] = short_success.apply(lambda row: (row['Entry Price'] - row['Highest point on the way to the 20th Percentile']) / row['Entry Price'] * 100 if pd.notnull(row['Highest point on the way to the 20th Percentile']) else None, axis=1)\n","\n","    return long_success, short_success"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZNIJemd3rMfc"},"outputs":[],"source":["def failure_sheet(scrip_df, new_long_20th_not_achieved_df, new_short_20th_not_achieved_df, twentieth_percentile_long, twentieth_percentile_short):\n","    # Extract relevant columns from long and short trades dataframes\n","    long_failure = new_long_20th_not_achieved_df[['Signal No.', 'Type of Signal', 'Entry Date', 'Exit Date', 'Entry Price', 'Exit Price', 'Days in Trade', 'Highest Point', 'Highest Point %', '20th Percentile Reached?', 'Opening = Highest']].copy()\n","    short_failure = new_short_20th_not_achieved_df[['Signal No.', 'Type of Signal', 'Entry Date', 'Exit Date', 'Entry Price', 'Exit Price', 'Days in Trade', 'Lowest Point', 'Lowest Point %',  '20th Percentile Reached?', 'Opening = Lowest']].copy()\n","\n","    # Calculate the lowest point in the trade for long and short failures\n","    long_failure.loc[:, 'Lowest Point in the Trade'] = long_failure.apply(lambda row: scrip_df[(scrip_df.index >= row['Entry Date']) & (scrip_df.index <= row['Exit Date'])]['Low'].min(), axis=1)\n","    short_failure.loc[:, 'Lowest Point in the Trade'] = short_failure.apply(lambda row: scrip_df[(scrip_df.index >= row['Entry Date']) & (scrip_df.index <= row['Exit Date'])]['Low'].min(), axis=1)\n","\n","    # Calculate lowest point % for long and short failures\n","    long_failure.loc[:, 'Lowest Point % (20th Not Achieved)'] = long_failure.apply(lambda row: (row['Lowest Point in the Trade'] - row['Entry Price']) / row['Entry Price'] * 100, axis=1)\n","    short_failure.loc[:, 'Lowest Point % (20th Not Achieved)'] = short_failure.apply(lambda row: (row['Lowest Point in the Trade'] - row['Entry Price']) / row['Entry Price'] * 100, axis=1)\n","\n","    return long_failure, short_failure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RwtGZKcerOKK"},"outputs":[],"source":["def final_output_long(new_long_trade_results_df, long_success, long_failure):\n","    # 80th Percentile time of highest point\n","    new_long_trade_results_df['Days for reaching Highest Point'] = pd.to_numeric(new_long_trade_results_df['Days for reaching Highest Point'], errors='coerce')\n","    time_highest_point_80th = new_long_trade_results_df['Days for reaching Highest Point'].quantile(0.8)\n","\n","    # 80th Percentile time of 20th Percentile\n","    long_success['Days for 20th Percentile'] = pd.to_numeric(long_success['Days for 20th Percentile'], errors='coerce')\n","    time_20th_percentile_80th = long_success['Days for 20th Percentile'].quantile(0.8)\n","\n","    # 20th Percentile of lowest point for achievement of 20th Percentile\n","    lowest_point_20th_achieved_20th = long_success['Lowest Point %'].quantile(0.2)\n","\n","    # 20th Percentile of lowest point for trades not achieving the 20th Percentile\n","    lowest_point_20th_not_achieved_20th = long_failure['Lowest Point % (20th Not Achieved)'].quantile(0.2)\n","\n","    return time_highest_point_80th, time_20th_percentile_80th, lowest_point_20th_achieved_20th, lowest_point_20th_not_achieved_20th"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsvZzxY4rRVR"},"outputs":[],"source":["def final_output_short(new_short_trade_results_df, short_success, short_failure):\n","    # 80th Percentile time of lowest point\n","    new_short_trade_results_df['Days for reaching Lowest Point'] = pd.to_numeric(new_short_trade_results_df['Days for reaching Lowest Point'], errors='coerce')\n","    time_lowest_point_80th = new_short_trade_results_df['Days for reaching Lowest Point'].quantile(0.8)\n","\n","    # 80th Percentile time of 20th Percentile\n","    short_success['Days for 20th Percentile'] = pd.to_numeric(short_success['Days for 20th Percentile'], errors='coerce')\n","    time_20th_percentile_80th = short_success['Days for 20th Percentile'].quantile(0.8)\n","\n","    # 20th Percentile of highest point for achievement of 20th Percentile\n","    highest_point_20th_achieved_20th = short_success['Highest Point %'].quantile(0.2)\n","\n","    # 20th Percentile of lowest point for trades not achieving the 20th Percentile\n","    lowest_point_20th_not_achieved_20th = short_failure['Lowest Point % (20th Not Achieved)'].quantile(0.2)\n","\n","    return time_lowest_point_80th, time_20th_percentile_80th, highest_point_20th_achieved_20th, lowest_point_20th_not_achieved_20th\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ZQRJmfbkS2n"},"outputs":[],"source":["# Path to the Excel file containing stock data\n","file_path = '/content/drive/MyDrive/Data/DATA_FOR_TESTING_P2.xlsx'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gg8QI2a3kX3W"},"outputs":[],"source":["# Path to the Excel file containing EMA combinations\n","ema_combinations_file_path ='/content/drive/MyDrive/Data/EMA_COMBOS.xlsx'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Svxp8Q8kZTY"},"outputs":[],"source":["# Get stock data from Excel file\n","stock_data = get_stock_data_from_excel(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JfnmY0CBkbsw"},"outputs":[],"source":["# Get EMA combinations from Excel file\n","ema_combinations = get_ema_combinations(ema_combinations_file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBqSj5O1kdxs"},"outputs":[],"source":["starting_equity = 100000  # Initial equity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wz6jxKiDk4yf"},"outputs":[],"source":["# Initialize lists to store all Long and Short results for all stocks\n","all_long_final_output = []\n","all_short_final_output = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWDN2H9cBpwH"},"outputs":[],"source":["count=1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"e0mPDL_RkfbD","outputId":"96503d14-eee6-4174-ee0c-7f225ba19786"},"outputs":[{"name":"stdout","output_type":"stream","text":["1. Processing SAIL...\n","2. Processing SBICARD...\n","3. Processing SBILIFE...\n","4. Processing SBIN...\n","5. Processing SHREECEM...\n","6. Processing SHRIRAMFIN...\n","7. Processing SIEMENS...\n","8. Processing SRF...\n","9. Processing SUNPHARMA...\n","10. Processing SUNTV...\n","11. Processing SYNGENE...\n","12. Processing TATACHEM...\n","13. Processing TATACOMM...\n","14. Processing TATACONSUM...\n","15. Processing TATAMOTORS...\n","16. Processing TATAPOWER...\n","17. Processing TATASTEEL...\n","18. Processing TCS...\n","19. Processing TECHM...\n","20. Processing TITAN...\n","21. Processing TORNTPHARM...\n","22. Processing TRENT...\n","23. Processing TVSMOTOR...\n","24. Processing UBL...\n","25. Processing ULTRACEMCO...\n","26. Processing UPL...\n","27. Processing VEDL...\n","28. Processing VOLTAS...\n","29. Processing WIPRO...\n","30. Processing ZEEL...\n"]}],"source":["# Run the analysis for each selected stock\n","for stock_symbol in stock_data.keys():\n","    print(f\"{count}. Processing {stock_symbol}...\")\n","    count+=1\n","\n","    try:\n","        data = stock_data[stock_symbol]\n","\n","        # Iterate over each combination of Fast and Slow EMAs\n","        for _, ema_combo in ema_combinations.iterrows():\n","            fast_ema_period = int(ema_combo['Fast EMA'])\n","            slow_ema_period = int(ema_combo['Slow EMA'])\n","\n","            # Iterate over signal periods from 5 to 55 (in range(5,31))\n","            for signal_period in [5,8,13,21,25,29,34]:\n","                # Run the SCRIP dataframe creation\n","                scrip_df = create_scrip_dataframe(data, fast_ema_period, slow_ema_period, signal_period)\n","\n","                # Generate trade results\n","                trade_results_df = create_trade_results(scrip_df)\n","\n","                # Separate the trade results into Long and Short trade results\n","                long_trade_results_df = trade_results_df[trade_results_df['Type of Signal'] == 'Long'].reset_index(drop=True)\n","                short_trade_results_df = trade_results_df[trade_results_df['Type of Signal'] == 'Short'].reset_index(drop=True)\n","\n","                # Calculate financial metrics\n","                long_trade_results_df = calculate_financial_metrics(long_trade_results_df, starting_equity)\n","                short_trade_results_df = calculate_financial_metrics(short_trade_results_df, starting_equity)\n","\n","                # Generate analysis for Long and Short trade results separately\n","                long_analysis_df, twentieth_percentile_long = create_analysis_dataframe(long_trade_results_df, 'Long', stock_symbol, fast_ema_period, slow_ema_period, signal_period, starting_equity)\n","                short_analysis_df, twentieth_percentile_short = create_analysis_dataframe(short_trade_results_df, 'Short', stock_symbol, fast_ema_period, slow_ema_period, signal_period, starting_equity)\n","\n","\n","                #GENERATE NEW TRADE RESULTS\n","                new_trade_results_df = new_trade_results(scrip_df, twentieth_percentile_long, twentieth_percentile_short)\n","\n","                # Separate new trade results into long and short\n","                new_long_trade_results_df = new_trade_results_df[new_trade_results_df['Type of Signal'] == 'Long'].reset_index(drop=True)\n","                new_short_trade_results_df = new_trade_results_df[new_trade_results_df['Type of Signal'] == 'Short'].reset_index(drop=True)\n","                # Separate new long and short trade results into two dataframes based on 20th Percentile achieved or not\n","                new_long_20th_achieved_df = new_long_trade_results_df[new_long_trade_results_df['20th Percentile Reached?'] == 'YES'].reset_index(drop=True)\n","                new_long_20th_not_achieved_df = new_long_trade_results_df[new_long_trade_results_df['20th Percentile Reached?'] == 'NO'].reset_index(drop=True)\n","                new_short_20th_achieved_df = new_short_trade_results_df[new_short_trade_results_df['20th Percentile Reached?'] == 'YES'].reset_index(drop=True)\n","                new_short_20th_not_achieved_df = new_short_trade_results_df[new_short_trade_results_df['20th Percentile Reached?'] == 'NO'].reset_index(drop=True)\n","\n","\n","                #GENERATE SUCCESS AND FAILURE SHEETS\n","                long_success, short_success = success_sheet(scrip_df, new_long_20th_achieved_df, new_short_20th_achieved_df, twentieth_percentile_long, twentieth_percentile_short)\n","                long_failure, short_failure = failure_sheet(scrip_df, new_long_20th_not_achieved_df, new_short_20th_not_achieved_df, twentieth_percentile_long, twentieth_percentile_short)\n","\n","                #Generate final output sheets for long and short trades\n","\n","                # Initialize new DataFrames for final output, copying the analysis dataframes\n","                final_output_long_df = long_analysis_df.copy()\n","                final_output_short_df = short_analysis_df.copy()\n","\n","                # Calculate the metrics for final output\n","                time_highest_point_80th_long, time_20th_percentile_80th_long, lowest_point_20th_achieved_20th_long, lowest_point_20th_not_achieved_20th_long = final_output_long(new_long_trade_results_df, long_success, long_failure)\n","                time_lowest_point_80th_short, time_20th_percentile_80th_short, highest_point_20th_achieved_20th_short, lowest_point_20th_not_achieved_20th_short = final_output_short(new_short_trade_results_df, short_success, short_failure)\n","\n","                # Add the new metrics to the analysis dataframes\n","                final_output_long_df['80th Percentile Time of Highest Point'] = time_highest_point_80th_long\n","                final_output_long_df['80th Percentile Time of 20th Percentile'] = time_20th_percentile_80th_long\n","                final_output_long_df['20th Percentile of Lowest Point (20th Achieved)'] = lowest_point_20th_achieved_20th_long\n","                final_output_long_df['20th Percentile of Lowest Point (20th Not Achieved)'] = lowest_point_20th_not_achieved_20th_long\n","\n","                final_output_short_df['80th Percentile Time of Lowest Point'] = time_lowest_point_80th_short\n","                final_output_short_df['80th Percentile Time of 20th Percentile'] = time_20th_percentile_80th_short\n","                final_output_short_df['20th Percentile of Highest Point (20th Achieved)'] = highest_point_20th_achieved_20th_short #Changed Lowest to Highest\n","                final_output_short_df['20th Percentile Lowest Point (20th Not Achieved)'] = lowest_point_20th_not_achieved_20th_short\n","\n","                # Store the analysis results for all stocks\n","                all_long_final_output.append(final_output_long_df)\n","                all_short_final_output.append(final_output_short_df)\n","\n","    except Exception as e:\n","        print(f\"Error processing {stock_symbol}: {e}\")\n","        continue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wSXIzpWUknfc"},"outputs":[],"source":["# Concatenate the analysis results for all stocks into two DataFrames\n","final_long_output_df = pd.concat(all_long_final_output, ignore_index=True)\n","final_short_output_df = pd.concat(all_short_final_output, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_0k4N6plVaI"},"outputs":[],"source":["# Save analysis to Excel\n","output_file_path = '/content/drive/MyDrive/Analysis/Categorize Trades/AllStocks_MACD_Analysis (Part 2).xlsx'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HfXkTneflh0G"},"outputs":[],"source":["with pd.ExcelWriter(output_file_path, engine='openpyxl', mode='w') as writer:\n","    final_long_output_df.to_excel(writer, sheet_name='Final Output Long', index=False)\n","    final_short_output_df.to_excel(writer, sheet_name='Final Output Short', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZB_W_P3CliHD"},"outputs":[],"source":["# Confirm file save\n","print(f\"Data saved to {output_file_path}\")"]}],"metadata":{"colab":{"provenance":[{"file_id":"1g8laEpdl4qm-VgH_yf0QUq7WbVG-4V2n","timestamp":1725547884387}],"mount_file_id":"1gVJOmj0UngAYwJvF28-Mz3bE38B1GpL3","authorship_tag":"ABX9TyNh2Ho6Jw6qVbdQeVHnciYO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}