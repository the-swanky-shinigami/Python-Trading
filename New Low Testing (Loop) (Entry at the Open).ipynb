{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1j5Z1H_soWJGf5sYolHcNMVVOAzNnKAhY","authorship_tag":"ABX9TyNjnkiUya7LTOBjyPFVii8C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xzkPf5MLhCT2","executionInfo":{"status":"ok","timestamp":1723621735247,"user_tz":-330,"elapsed":1096,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["# Function to read stock data from an Excel file\n","def get_stock_data_from_excel(file_path):\n","    all_stock_data = pd.read_excel(file_path, sheet_name=None)\n","    stock_data = {}\n","\n","    for sheet_name, data in all_stock_data.items():\n","        # Ensure 'Date' is treated as a datetime column and set as index\n","        data['Date'] = pd.to_datetime(data['Date'])\n","        data.set_index('Date', inplace=True)\n","        stock_data[sheet_name] = data\n","\n","    return stock_data"],"metadata":{"id":"ELcuJejahrIc","executionInfo":{"status":"ok","timestamp":1723621735248,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def create_scrip_data(df, N):\n","    N_half = N // 2\n","\n","    # Initialize the Scrip_Data DataFrame with required columns\n","    scrip_data = pd.DataFrame(index=df.index)\n","    scrip_data['Close'] = df['Close']\n","    scrip_data['Open'] = df['Open']\n","    scrip_data['High'] = df['High']\n","    scrip_data['Low'] = df['Low']\n","    scrip_data['Volume'] = df['Volume']\n","\n","    # Calculate Previous N days Low\n","    scrip_data[f'Previous {N} days Low'] = df['Close'].rolling(window=N, min_periods=1).min().shift(1)\n","\n","    # Calculate Today's Closing Higher for rows starting from N+1 onwards\n","    scrip_data['Today\\'s Closing Lower'] = ''  # Initialize with NaN\n","\n","    # Calculate Today's Closing Lower\n","    for i in range(N, len(scrip_data)):\n","        scrip_data.loc[scrip_data.index[i], 'Today\\'s Closing Lower'] = (\n","            'YES' if scrip_data['Close'].iloc[i] < scrip_data[f'Previous {N} days Low'].iloc[i] else 'NO'\n","        )\n","\n","    # Initialize the Enter Trade and Trade Number columns, but only calculate for rows starting from N+1 onwards\n","    scrip_data['Enter Trade'] = ''  # Initialize with NaN\n","    scrip_data['Trade Number'] = pd.NA  # Initialize with NaN\n","\n","    # Calculate Trade taken in last N/2 days, Enter Trade, and Trade Number\n","    trade_taken = [0] * len(scrip_data)  # This will track the count of \"ENTER\" trades\n","    trade_number = 0\n","\n","    for i in range(N, len(scrip_data)):\n","        last_n_half_days = scrip_data['Enter Trade'].iloc[i-N_half:i]\n","        trade_taken[i] = last_n_half_days[last_n_half_days == 'ENTER'].count()\n","\n","        if scrip_data['Today\\'s Closing Lower'].iloc[i] == 'YES' and trade_taken[i] == 0:\n","            scrip_data.loc[scrip_data.index[i], 'Enter Trade'] = 'ENTER'\n","            trade_number += 1\n","        else:\n","            scrip_data.loc[scrip_data.index[i], 'Enter Trade'] = 'NA'\n","\n","        scrip_data.loc[scrip_data.index[i], 'Trade Number'] = trade_number\n","\n","    # Add the new column: Trade taken in last N_half days, only for rows starting from N+1 onwards\n","    scrip_data[f'Trade taken in last {N_half} days'] = pd.NA  # Initialize with NaN\n","    for i in range(N, len(scrip_data)):\n","        scrip_data.loc[scrip_data.index[i], f'Trade taken in last {N_half} days'] = trade_taken[i]\n","\n","    # Calculate N/2th Day, counting the entry day, only for rows starting from N+1 onwards\n","    scrip_data[f'{N_half}th Day'] = pd.NA  # Initialize with NaN\n","    for i in range(N, len(scrip_data)):\n","        if i + N_half - 1 < len(scrip_data):\n","            scrip_data.loc[scrip_data.index[i], f'{N_half}th Day'] = scrip_data.index[i + N_half - 1]\n","\n","    return scrip_data"],"metadata":{"id":"vwIDA06VhsVj","executionInfo":{"status":"ok","timestamp":1723621735248,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def create_trade_data(scrip_data, N):\n","    trade_data = []\n","    N_half = N // 2\n","    trades = scrip_data[scrip_data['Enter Trade'] == 'ENTER']\n","\n","    for index, trade in trades.iterrows():\n","        trade_number = trade['Trade Number']\n","        entry_day = index\n","        nth_day = trade[f'{N_half}th Day']\n","        entry_price = trade['Close']\n","\n","        # Adjust entry to be at the open of the next day\n","        next_day_index = scrip_data.index.get_loc(entry_day) + 1\n","        if next_day_index >= len(scrip_data):\n","            continue  # Skip if the next day is out of bounds\n","\n","        next_day_data = scrip_data.iloc[next_day_index]\n","        entry_day = next_day_data.name  # Update entry_day to the next day\n","        entry_price = next_day_data['Open']\n","\n","        # Calculate the N/2th day based on the adjusted entry day\n","        nth_day_index = next_day_index + (N_half - 1)\n","        if nth_day_index >= len(scrip_data):\n","            continue  # Skip if N_halfth day is out of bounds\n","\n","        nth_day = scrip_data.index[nth_day_index]\n","\n","        # Include the high for both entry and exit days in the calculation\n","        trade_period = scrip_data.loc[entry_day:nth_day]\n","        highest_point = max(trade_period['High'].max(), next_day_data['High'])\n","        lowest_point = min(trade_period['Low'].min(), next_day_data['Low'])\n","\n","        highest_point_date = trade_period['High'].idxmax()\n","        lowest_point_date = trade_period['Low'].idxmin()\n","\n","        long_potential = ((highest_point - entry_price) / entry_price) * 100\n","        short_potential = ((entry_price - lowest_point) / entry_price) * 100\n","\n","        whipsaw_long = 'Yes' if long_potential < 0 else 'No'\n","        whipsaw_short = 'Yes' if short_potential < 0 else 'No'\n","\n","        reached_first = 'Lowest' if lowest_point_date < highest_point_date else 'Highest'\n","\n","        trade_data.append({\n","            'Trade Number': trade_number,\n","            'Entry Day': entry_day,  # Now reflects the next day\n","            f'{N_half}th Day': nth_day,  # Adjusted N_halfth day\n","            'Entry Price': entry_price,\n","            'Highest Point': highest_point,\n","            'Lowest Point': lowest_point,\n","            'Long Potential': long_potential,\n","            'Short Potential': short_potential,\n","            'Whipsaw Long': whipsaw_long,\n","            'Whipsaw Short': whipsaw_short,\n","            'Date of Highest Point': highest_point_date,\n","            'Date of Lowest Point': lowest_point_date,\n","            'Reached First?': reached_first\n","        })\n","\n","    trade_df = pd.DataFrame(trade_data)\n","\n","    return trade_df\n"],"metadata":{"id":"yG609SL4htwH","executionInfo":{"status":"ok","timestamp":1723621735248,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def create_analysis(trade_data, N):\n","    N_half = N // 2\n","\n","    # Calculate required metrics for the Analysis dataframe\n","    total_trades = len(trade_data)\n","\n","    long_potential_30th_percentile = trade_data['Long Potential'].quantile(0.30)\n","    short_potential_30th_percentile = trade_data['Short Potential'].quantile(0.30)\n","\n","    long_whipsaws_count = trade_data['Whipsaw Long'].value_counts().get('Yes', 0)\n","    short_whipsaws_count = trade_data['Whipsaw Short'].value_counts().get('Yes', 0)\n","\n","    short_reached_first = trade_data['Reached First?'].value_counts().get('Highest', 0)\n","    long_reached_first = trade_data['Reached First?'].value_counts().get('Lowest', 0)\n","\n","    # Create a dictionary to store the analysis data\n","    analysis_data = {\n","        'LookBack Period': N,\n","        'N/2': N_half,\n","        'Total Trades': total_trades,\n","        '30th Percentile Long Potential': long_potential_30th_percentile,\n","        '30th Percentile Short Potential': short_potential_30th_percentile,\n","        'Long Whipsaws Count': long_whipsaws_count,\n","        'Short Whipsaws Count': short_whipsaws_count,\n","        'Short Reached First': short_reached_first,\n","        'Long Reached First': long_reached_first\n","    }\n","\n","    # Convert the dictionary to a DataFrame\n","    analysis_df = pd.DataFrame([analysis_data])\n","\n","    return analysis_df"],"metadata":{"id":"xws1bYVyhv2Y","executionInfo":{"status":"ok","timestamp":1723621735248,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Path to the Excel file containing stock data\n","file_path = '/content/drive/MyDrive/Data/DATA_FOR_TESTING.xlsx'\n","output_file_path = '/content/drive/MyDrive/Analysis/ENTRY AT THE OPEN/New Low Testing/AllStocks_Analysis.xlsx'\n"],"metadata":{"id":"M3Mx5EUohxUs","executionInfo":{"status":"ok","timestamp":1723621735248,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Get stock data from Excel file\n","stock_data = get_stock_data_from_excel(file_path)"],"metadata":{"id":"trKxNMjMhzyD","executionInfo":{"status":"ok","timestamp":1723621782099,"user_tz":-330,"elapsed":46853,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["all_analysis_results = []"],"metadata":{"id":"dMp-TeqYh1Tv","executionInfo":{"status":"ok","timestamp":1723621782100,"user_tz":-330,"elapsed":15,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["for scrip, df in stock_data.items():\n","    print(f\"Processing {scrip}...\")\n","    # Looping N from 5 to 55\n","    for N in range(5, 56):\n","        scrip_data = create_scrip_data(df, N=N)\n","        trade_data = create_trade_data(scrip_data, N=N)\n","        analysis_data = create_analysis(trade_data, N=N)\n","\n","        # Add the Scrip name as the first column\n","        analysis_data.insert(0, 'Scrip', scrip)\n","\n","        all_analysis_results.append(analysis_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTklPqeWh1v8","executionInfo":{"status":"ok","timestamp":1723636682458,"user_tz":-330,"elapsed":1735722,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}},"outputId":"4aed2dfa-e7c5-40fa-e21a-507a28dfe017"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing AARTIIND...\n","Processing ABB...\n","Processing ABBOTINDIA...\n","Processing ABCAPITAL...\n","Processing ABFRL...\n","Processing ACC...\n","Processing ADANIENT...\n","Processing ADANIPORTS...\n","Processing ALKEM...\n","Processing AMBUJACEM...\n","Processing APOLLOHOSP...\n","Processing APOLLOTYRE...\n","Processing ASHOKLEY...\n","Processing ASIANPAINT...\n","Processing ASTRAL...\n","Processing ATUL...\n","Processing AUBANK...\n","Processing AUROPHARMA...\n","Processing AXISBANK...\n","Processing BAJAJ-AUTO...\n","Processing BAJAJFINSV...\n","Processing BAJFINANCE...\n","Processing BALKRISIND...\n","Processing BALRAMCHIN...\n","Processing BANDHANBNK...\n","Processing BANKBARODA...\n","Processing BATAINDIA...\n","Processing BEL...\n","Processing BERGEPAINT...\n","Processing BHARATFORG...\n","Processing BHARTIARTL...\n","Processing BHEL...\n","Processing BIOCON...\n","Processing BOSCHLTD...\n","Processing BPCL...\n","Processing BRITANNIA...\n","Processing BSOFT...\n","Processing CANBK...\n","Processing CANFINHOME...\n","Processing CHAMBLFERT...\n","Processing CHOLAFIN...\n","Processing CIPLA...\n","Processing COALINDIA...\n","Processing COFORGE...\n","Processing COLPAL...\n","Processing CONCOR...\n","Processing COROMANDEL...\n","Processing CROMPTON...\n","Processing CUB...\n","Processing CUMMINSIND...\n","Processing DABUR...\n","Processing DALBHARAT...\n","Processing DEEPAKNTR...\n","Processing DIVISLAB...\n","Processing DIXON...\n","Processing DLF...\n","Processing DRREDDY...\n","Processing EICHERMOT...\n","Processing ESCORTS...\n","Processing EXIDEIND...\n","Processing FEDERALBNK...\n","Processing GAIL...\n","Processing GLENMARK...\n","Processing GMRINFRA...\n","Processing GNFC...\n","Processing GODREJCP...\n","Processing GODREJPROP...\n","Processing GRANULES...\n","Processing GRASIM...\n","Processing GUJGASLTD...\n","Processing HAL...\n","Processing HAVELLS...\n","Processing HCLTECH...\n","Processing HDFCAMC...\n","Processing HDFCBANK...\n","Processing HDFCLIFE...\n","Processing HEROMOTOCO...\n","Processing HINDALCO...\n","Processing HINDCOPPER...\n","Processing HINDPETRO...\n","Processing HINDUNILVR...\n","Processing ICICIBANK...\n","Processing ICICIGI...\n","Processing ICICIPRULI...\n","Processing IDEA...\n","Processing IDFC...\n","Processing IDFCFIRSTB...\n","Processing IEX...\n","Processing IGL...\n","Processing INDHOTEL...\n","Processing INDIACEM...\n","Processing INDIAMART...\n","Processing INDIGO...\n","Processing INDUSINDBK...\n","Processing INDUSTOWER...\n","Processing INFY...\n","Processing IOC...\n","Processing IPCALAB...\n","Processing IRCTC...\n","Processing ITC...\n","Processing JINDALSTEL...\n","Processing JKCEMENT...\n","Processing JSWSTEEL...\n","Processing JUBLFOOD...\n","Processing KOTAKBANK...\n","Processing LALPATHLAB...\n","Processing LAURUSLABS...\n","Processing LICHSGFIN...\n","Processing LT...\n","Processing LTIM...\n","Processing LTTS...\n","Processing LUPIN...\n","Processing M&M...\n","Processing M&MFIN...\n","Processing MANAPPURAM...\n","Processing MARICO...\n","Processing MARUTI...\n","Processing MCDOWELL-N...\n","Processing MCX...\n","Processing METROPOLIS...\n","Processing MFSL...\n","Processing MGL...\n","Processing MOTHERSON...\n","Processing MPHASIS...\n","Processing MRF...\n","Processing MUTHOOTFIN...\n","Processing NATIONALUM...\n","Processing NAUKRI...\n","Processing NAVINFLUOR...\n","Processing NESTLEIND...\n","Processing NMDC...\n","Processing NTPC...\n","Processing OBEROIRLTY...\n","Processing OFSS...\n","Processing ONGC...\n","Processing PAGEIND...\n","Processing PEL...\n","Processing PERSISTENT...\n","Processing PETRONET...\n","Processing PFC...\n","Processing PIDILITIND...\n","Processing PIIND...\n","Processing PNB...\n","Processing POLYCAB...\n","Processing POWERGRID...\n","Processing PVRINOX...\n","Processing RAMCOCEM...\n","Processing RBLBANK...\n","Processing RECLTD...\n","Processing RELIANCE...\n","Processing SAIL...\n","Processing SBICARD...\n","Processing SBILIFE...\n","Processing SBIN...\n","Processing SHREECEM...\n","Processing SHRIRAMFIN...\n","Processing SIEMENS...\n","Processing SRF...\n","Processing SUNPHARMA...\n","Processing SUNTV...\n","Processing SYNGENE...\n","Processing TATACHEM...\n","Processing TATACOMM...\n","Processing TATACONSUM...\n","Processing TATAMOTORS...\n","Processing TATAPOWER...\n","Processing TATASTEEL...\n","Processing TCS...\n","Processing TECHM...\n","Processing TITAN...\n","Processing TORNTPHARM...\n","Processing TRENT...\n","Processing TVSMOTOR...\n","Processing UBL...\n","Processing ULTRACEMCO...\n","Processing UPL...\n","Processing VEDL...\n","Processing VOLTAS...\n","Processing WIPRO...\n","Processing ZEEL...\n","Processing ZYDUSLIFE...\n"]}]},{"cell_type":"code","source":["# Combine all analysis results for all scrips into a single DataFrame\n","combined_analysis_df = pd.concat(all_analysis_results, ignore_index=True)"],"metadata":{"id":"0KpSjywah3QB","executionInfo":{"status":"ok","timestamp":1723636683272,"user_tz":-330,"elapsed":809,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Save the combined analysis results to a single Excel sheet\n","with pd.ExcelWriter(output_file_path) as writer:\n","    combined_analysis_df.to_excel(writer, sheet_name='Combined Analysis', index=False)"],"metadata":{"id":"rkQzKKdgh5GF","executionInfo":{"status":"ok","timestamp":1723636685540,"user_tz":-330,"elapsed":2270,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["print(f\"Processed data saved to {output_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBVvHq9Fh6SO","executionInfo":{"status":"ok","timestamp":1723636685550,"user_tz":-330,"elapsed":7,"user":{"displayName":"Saumya Dwivedi","userId":"06991737587028914304"}},"outputId":"0eb7d66f-d9fc-49e7-b2ae-777c96452551"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed data saved to /content/drive/MyDrive/Analysis/ENTRY AT THE OPEN/New Low Testing/AllStocks_Analysis.xlsx\n"]}]}]}